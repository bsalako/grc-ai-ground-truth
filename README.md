# GRC AI Ground Truth Dataset

Hello, this repository contains structured datasets, rating guides, and methodology for evaluating AI-generated outputs against real-world **Governance, Risk & Compliance (GRC)** standards.

## ðŸ“Œ Purpose

This repository demonstrates how to:
- Define a **ground truth dataset** for compliance questions
- Build reproducible truth-checking methods
- Evaluate AI responses against audit-ready expectations

It is useful for:
- AI evaluation projects
- Compliance automation research
## ðŸ§© Directory Structure
datasets/ â€” Ground truth CSVs

rating_guides/ â€” Evaluation criteria and guides

edge_cases/ â€” Complex GRC scenarios

methodology/ â€” How ground truth was constructed


## ðŸš€ Getting Started

1. Browse the datasets in `datasets/`
2. Review the rating guide in `rating_guides/`
3. Explore edge cases in `edge_cases/`
4. Read the methodology for context

The methodology in methodology/how_ground_truth_is_built.md defines how truth, risk, and AI evaluation standards are governed across this repository.
